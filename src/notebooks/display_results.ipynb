{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.data_fcts import *\n",
    "from src.retrain_fcts import *\n",
    "\n",
    "from src.bench_fcts import *\n",
    "from src.viz_fcts import *\n",
    "from ast import literal_eval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List generate df functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List all results\n",
    "\n",
    "4010 : comparative Shap backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = os.environ.get(\"RESULTS_ROOT_PATH\")+'/final_run'\n",
    "print(results_path)\n",
    "\n",
    "results = os.listdir(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_list(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of all datasets with some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_list = {name: get_expe_list(name, results) for name in get_dataset_list(results)}\n",
    "exp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List generate df functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_noises = [0, 0.001, 0.01, 0.05, 0.1, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 3000\n",
    "n_features = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_smooth_concept_drift(n_samples = n_samples, n_features = n_features):\n",
    "    D_G = Drift_generators(n_samples = n_samples, n_features = n_features)\n",
    "    D_G.smooth_concept_drift(n_drift=1)\n",
    "    return(D_G)\n",
    "\n",
    "def generate_abrupt_concept_drift(n_samples = n_samples, n_features = n_features):\n",
    "    D_G = Drift_generators(n_samples = n_samples, n_features = n_features)\n",
    "    D_G.abrupt_concept_drift(n_drift=1)\n",
    "    return(D_G)\n",
    "\n",
    "def generate_gradual_concept_drift(n_samples = n_samples, n_features = n_features):\n",
    "    D_G = Drift_generators(n_samples = n_samples, n_features = n_features)\n",
    "    D_G.gradual_concept_drift(n_drift=1)\n",
    "    return(D_G)\n",
    "\n",
    "def generate_abrupt_covariate_drift(n_samples = n_samples, n_features = n_features):\n",
    "    D_G = Drift_generators(n_samples = n_samples, n_features = n_features)\n",
    "    d_centers = [(0, 0,\n",
    "    0.3, 0.25, 1),(0, 0.3, 0.5, 0, 0.25),(0, 0.5, 1, 0.25, 1)]\n",
    "    D_G.abrupt_covariate_drift(d_centers=d_centers)\n",
    "    return(D_G)\n",
    "\n",
    "normal_fcts = [generate_smooth_concept_drift, generate_abrupt_concept_drift,\n",
    "               generate_gradual_concept_drift, generate_abrupt_covariate_drift]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generate_drift_fcts = []\n",
    "for noise_rate in all_noises:\n",
    "    # NOISY \n",
    "    def generate_noisy_smooth_concept_drift(n_samples = n_samples, noise_rate=noise_rate):\n",
    "        D_G = Drift_generators(n_samples = n_samples, n_features = n_features)\n",
    "        D_G.smooth_concept_drift(n_drift=1)\n",
    "        D_G.add_noise(noise_rate=noise_rate)\n",
    "        return(D_G)\n",
    "\n",
    "    def generate_noisy_abrupt_concept_drift(n_samples = n_samples, noise_rate=noise_rate):\n",
    "        D_G = Drift_generators(n_samples = n_samples, n_features = n_features)\n",
    "        D_G.abrupt_concept_drift(n_drift=1)\n",
    "        D_G.add_noise(noise_rate=noise_rate)\n",
    "        return(D_G)\n",
    "\n",
    "    def generate_noisy_gradual_concept_drift(n_samples = n_samples, noise_rate=noise_rate):\n",
    "        D_G = Drift_generators(n_samples = n_samples, n_features = n_features)\n",
    "        D_G.gradual_concept_drift(n_drift=1)\n",
    "        D_G.add_noise(noise_rate=noise_rate)\n",
    "        return(D_G)\n",
    "\n",
    "    def generate_noisy_abrupt_covariate_drift(n_samples = n_samples, noise_rate=noise_rate):\n",
    "        D_G = Drift_generators(n_samples = n_samples, n_features = n_features)\n",
    "        d_centers = [(0, 0,\n",
    "                    0.3, 0.25, 1),(0, 0.3, 0.5, 0, 0.25),(0, 0.5, 1, 0.25, 1)]\n",
    "        D_G.abrupt_covariate_drift(d_centers=d_centers)\n",
    "        D_G.add_noise(noise_rate=noise_rate)\n",
    "        return(D_G)\n",
    "\n",
    "\n",
    "\n",
    "            #generate_noisy_smooth_concept_drift\n",
    "    noisy_fcts = [generate_noisy_smooth_concept_drift, generate_noisy_abrupt_concept_drift, generate_noisy_abrupt_covariate_drift,\n",
    "                generate_noisy_gradual_concept_drift],\n",
    "                 #generate_noisy_abrupt_covariate_drift]\n",
    "                #generate_noisy_sine1, generate_noisy_sine2, generate_noisy_stagger]\n",
    "    generate_drift_fcts += noisy_fcts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_df_generate_fcts_special = []\n",
    "for noise_rate in all_noises:\n",
    "    # NOISY \n",
    "    def generate_noisy_stagger(noise_rate=noise_rate):\n",
    "        D_G = Drift_generators()\n",
    "        D_G.load_df(\"stagger_short\")\n",
    "        D_G.add_noise(noise_rate=noise_rate)\n",
    "        return(D_G)\n",
    "#\n",
    "    def generate_noisy_sine1(noise_rate=noise_rate):\n",
    "        D_G = Drift_generators()\n",
    "        D_G.load_df(\"sine1_short\")\n",
    "        D_G.add_noise(noise_rate=noise_rate)\n",
    "        return(D_G)\n",
    "#\n",
    "    def generate_noisy_sine2(noise_rate=noise_rate):\n",
    "        D_G = Drift_generators()\n",
    "        D_G.load_df(\"sine2_short\")\n",
    "        D_G.add_noise(noise_rate=noise_rate)\n",
    "        return(D_G)\n",
    "\n",
    "    noisy_fcts = [generate_noisy_stagger, generate_noisy_sine1, generate_noisy_sine2],\n",
    "    list_df_generate_fcts_special += noisy_fcts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generate_nodrift_fcts = []\n",
    "for noise_rate in all_noises:\n",
    "    # NOISY \n",
    "    def generate_nodrift_df(noise_rate=noise_rate):\n",
    "\n",
    "        D_G = Drift_generators(n_samples = n_samples, n_features = n_features)\n",
    "        D_G.abrupt_concept_drift(drifts=[Drift(is_abrupt=True,\n",
    "                                    start=n_samples-2,\n",
    "                                    characteristic=[0.7-0.3*(0 % 2) for i in range(D_G.n_features)])])\n",
    "        D_G.add_noise(noise_rate=noise_rate)\n",
    "        D_G.drift_name = f\"nodrift_noisy{str(noise_rate)[2:]}\"\n",
    "        \n",
    "        return(D_G)\n",
    "    generate_nodrift_fcts += [generate_nodrift_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fcts_selected = [a+b for a,b in zip(list_df_generate_fcts_special, generate_drift_fcts)]\n",
    "all_fcts_selected = [a+[b] for a,b in zip(all_fcts_selected, generate_nodrift_fcts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fcts_selected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show df metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_generate_fcts = np.ravel(all_fcts_selected)\n",
    "nodrift_funcs = generate_nodrift_fcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_G = list_df_generate_fcts[3]()\n",
    "print(D_G.drift_name)\n",
    "results = os.listdir(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in results if \"nodrift\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_G.drift_name.replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_metrics = get_D_G_metrics(D_G, results, selected_methods = [\"ADWIN\", \"PH\", \"KSWIN\"],\n",
    "                                  exp_type=\"df_reset\", noisy = True, path = results_path+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = ['no', 'false', 'min','mean', 'median', 'median_true', 'max', 'std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_metrics.loc[metrics_list].T.sort_values([\"no\",\"false\",\"median\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "D_G = list_df_generate_fcts[3]()\n",
    "print(D_G.drift_name)\n",
    "\n",
    "\n",
    "results = os.listdir(results_path)\n",
    "all_df_metrics = get_D_G_metrics(D_G, results, selected_methods = [\"ADWIN\", \"PH\", \"KSWIN\"], \n",
    "                exp_type=\"df_reset\", noisy=True, path =results_path+\"/\")\n",
    "metrics_list = ['no', 'false', 'min','mean', 'median', 'median_true', 'max', 'std']\n",
    "all_df_metrics.loc[\"median\"] = all_df_metrics.loc[\"median\"]-D_G.drift_points[0]\n",
    "all_df_metrics.loc[\"mean\"] = all_df_metrics.loc[\"mean\"]-D_G.drift_points[0]\n",
    "all_df_metrics.loc[metrics_list].T.sort_values([\"no\",\"false\",\"median\"]).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_to_latex(all_df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_generate_fcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_drift = [f for f in nodrift_funcs if \"nodrift\" in f.__name__]#[:3]\n",
    "single_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_G = single_drift[-1]()\n",
    "print(D_G.drift_name)\n",
    "results = os.listdir(results_path)\n",
    "\n",
    "all_df_metrics = get_D_G_metrics(D_G, results, selected_methods = [\"ADWIN\", \"PH\", \"KSWIN\"],\n",
    "                        exp_type=\"noisy\", noisy = True, path=results_path+\"/\")\n",
    "\n",
    "metrics_list = ['no', 'false', 'min','mean', 'median', 'median_true', 'max', 'std']\n",
    "\n",
    "all_df_metrics.loc[metrics_list].T.sort_values([\"no\",\"false\",\"median\"]).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Global overview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "D_G = list_df_generate_fcts[0]()\n",
    "print(D_G.drift_name)\n",
    "\n",
    "\n",
    "results = os.listdir(results_path)\n",
    "all_df_metrics = get_D_G_metrics(D_G, results, selected_methods = [\"ADWIN\", \"PH\", \"KSWIN\"], \n",
    "                exp_type=\"df_reset\", noisy=True, path =results_path+\"/\")\n",
    "metrics_list = ['prec','no', 'false', 'min','mean', 'median', 'median_true', 'max', 'std']\n",
    "all_df_metrics.loc[\"median\"] = all_df_metrics.loc[\"median\"]-D_G.drift_points[0]\n",
    "all_df_metrics.loc[\"mean\"] = all_df_metrics.loc[\"mean\"]-D_G.drift_points[0]\n",
    "all_df_metrics.loc[metrics_list].T.sort_values([\"prec\",\"median\"])#.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_metrics.loc['prec', all_df_metrics.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drift_type_from_name(drift_name):\n",
    "    drift_type = drift_name\n",
    "    if(\"sine\" not in drift_type):\n",
    "        drift_type = \"\".join([\"\" if x.isdigit() else x for x in drift_type ])\n",
    "    if(\"noisy\" in drift_type):\n",
    "        drift_type = \"\".join(drift_type.split(\"noisy\")[:-1])\n",
    "    drift_type = drift_type.replace(\" \",\"_\")\n",
    "    if(drift_type[-1] == \"_\"):\n",
    "        drift_type = drift_type[:-1]\n",
    "    return(drift_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenario_prec = pd.DataFrame(index = [f().drift_name for f in list_df_generate_fcts],\n",
    "                            columns = [\"_\".join(x.split(\"_\")[:-1])  if any([a.isdigit() for a in x]) else x for x in  all_df_metrics.columns])\n",
    "df_scenario_med = pd.DataFrame(index = [f().drift_name for f in list_df_generate_fcts],\n",
    "                    columns = [\"_\".join(x.split(\"_\")[:-1])  if any([a.isdigit() for a in x]) else x for x in  all_df_metrics.columns])\n",
    "for i, f in enumerate(list_df_generate_fcts):\n",
    "    D_G = f()\n",
    "    results = os.listdir(results_path)\n",
    "    all_df_metrics = get_D_G_metrics(D_G, results, selected_methods = [\"ADWIN\", \"PH\", \"KSWIN\"], \n",
    "                    exp_type=\"df_reset\", noisy=True, path =results_path+\"/\")\n",
    "    noiseless_columns = [\"_\".join(x.split(\"_\")[:-1])  if any([a.isdigit() for a in x]) else x for x in  all_df_metrics.columns]\n",
    "    precisions = all_df_metrics.loc['TP', all_df_metrics.columns].values\n",
    "    medians = all_df_metrics.loc['median', all_df_metrics.columns].values\n",
    "    df_scenario_med.loc[D_G.drift_name, noiseless_columns] = medians\n",
    "    df_scenario_prec.loc[D_G.drift_name, noiseless_columns] = precisions\n",
    "    \n",
    "    df_scenario_prec.loc[D_G.drift_name,\"noise_rate\"] = D_G.noise_rate\n",
    "    df_scenario_med.loc[D_G.drift_name,\"noise_rate\"]  = D_G.noise_rate\n",
    "    df_scenario_prec.loc[D_G.drift_name,\"drift_type\"] = get_drift_type_from_name(D_G.drift_name)\n",
    "    df_scenario_med.loc[D_G.drift_name,\"drift_type\"]  = get_drift_type_from_name(D_G.drift_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenario_med.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenario_prec.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenario_prec.loc[[x for x in df_scenario_prec.index if \"covariate\" in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenario_prec = df_scenario_prec.drop([x for x in df_scenario_prec.index if \"stagger_short\" in x])\n",
    "df_scenario_prec = df_scenario_prec.drop([x for x in df_scenario_prec.index if \"nodrift\" in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df_scenario_prec.noise_rate.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_res_diff_prec = compute_shap_diff(df_scenario_prec, max_noise = sorted(df_scenario_prec.noise_rate.unique())[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = df_res_diff_prec.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.arange(len(df_res_diff_prec.index))\n",
    "x = np.arange(len(df_res_diff_prec.columns))\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = df_res_diff_prec.values\n",
    "#Z = Z>=0 #THIS IS TO GO TO BOOLEAN Version\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"], N=256) \n",
    "fig, ax = plt.subplots(figsize = [7,3])\n",
    "pc = ax.pcolormesh(Z,norm=matplotlib.colors.CenteredNorm(), cmap=cmap)\n",
    "ax.set_yticks(np.arange(0.5,len(df_res_diff_prec.index)+0.5), df_res_diff_prec.index)\n",
    "ax.set_xticks(np.arange(0.5, len(df_res_diff_prec.columns)+0.5), [\"\".join(x.split(\"_\")[-1:]).upper() for x in df_res_diff_prec.columns])\n",
    "fig.colorbar(pc, ax=ax)\n",
    "#plt.title(\"Precision difference between Shap-detect and vanilla detector\")\n",
    "\n",
    "\n",
    "\n",
    "for (i, j), z in np.ndenumerate(Z):\n",
    "    ax.text(j+0.5, i+0.5, '{:0.2f}'.format(z), ha='center', va='center')\n",
    "\n",
    "\n",
    "save_path = os.environ.get(\"FIGURES_PATH\")\n",
    "save_path += 'global_prec_delta.png'\n",
    "print(save_path)\n",
    "plt.savefig(save_path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenario_med = df_scenario_med.drop([x for x in df_scenario_med.index if \"stagger_short\" in x])\n",
    "df_scenario_med = df_scenario_med.drop([x for x in df_scenario_med.index if \"nodrift\" in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df_scenario_med.noise_rate.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_diff_med = compute_shap_diff(df_scenario_med, max_noise = sorted(df_scenario_med.noise_rate.unique())[4])\n",
    "df_res_diff_med = df_res_diff_med.loc[[x for x in col_order if \"nodrift\" not in x]]#Keep same order as the above graph\n",
    "#df_res_diff_med = df_res_diff_med.drop(\"nodrift\")#no need keeping it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.arange(len(df_res_diff_med.index))\n",
    "x = np.arange(len(df_res_diff_med.columns))\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = df_res_diff_med.values\n",
    "#Z = Z>=0 #THIS IS TO GO TO BOOLEAN Version\n",
    "from  matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "cmap=LinearSegmentedColormap.from_list('rg',[\"r\", \"w\", \"g\"][::-1], N=256) \n",
    "fig, ax = plt.subplots(figsize = [7,3])\n",
    "pc = ax.pcolormesh(Z,norm=matplotlib.colors.CenteredNorm(), cmap=cmap)\n",
    "ax.set_yticks(np.arange(0.5,len(df_res_diff_med.index)+0.5), df_res_diff_med.index)\n",
    "ax.set_xticks(np.arange(0.5, len(df_res_diff_med.columns)+0.5), [\"\".join(x.split(\"_\")[-1:]).upper() for x in df_res_diff_med.columns])\n",
    "fig.colorbar(pc, ax=ax)\n",
    "#plt.title(\"Mean median detection difference between Shap-detect and vanilla detector\\nThe lower the better\")\n",
    "\n",
    "\n",
    "for (i, j), z in np.ndenumerate(Z):\n",
    "    ax.text(j+0.5, i+0.5, '{:.0f}'.format(z), ha='center', va='center')\n",
    "\n",
    "\n",
    "\n",
    "save_path = os.environ.get(\"FIGURES_PATH\")\n",
    "save_path += 'global_median_delta.png'\n",
    "print(save_path)\n",
    "plt.savefig(save_path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution of Median detection for a given Drift and algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = os.listdir(results_path)\n",
    "metrics_list = ['no', 'false', 'min','mean', 'median', 'median_true', 'max', 'std']\n",
    "\n",
    "for i,f in enumerate(single_drift[1:-1]):\n",
    "\n",
    "    D_G = f()#generate_abrupt_concept_drift(n_samples=5000)\n",
    "    print(D_G.drift_name)\n",
    "    all_df_metrics = get_D_G_metrics(D_G, results, selected_methods = [\"ADWIN\", \"PH\", \"KSWIN\"],\n",
    "                    exp_type=\"noisy\", noisy = True, path=results_path+\"/\")\n",
    "    if(i==0):\n",
    "        df_drift_res = all_df_metrics\n",
    "    else:\n",
    "        df_drift_res = pd.concat([df_drift_res, all_df_metrics], axis=1)\n",
    "    #all_df_metrics = all_df_metrics.loc[metrics_list].T.sort_values([\"no\",\"false\",\"median\"]).sort_index()\n",
    "    \n",
    "df_drift_res = df_drift_res.loc[metrics_list].T.sort_values([\"no\",\"false\",\"median\"]).sort_index()\n",
    "df_drift_res = df_drift_res.drop(columns = [\"no\",\"false\"])\n",
    "df = df_drift_res.copy()\n",
    "df['noise_rate'] = [x.split(\"_\")[-1] for x in df.index]\n",
    "df['algo'] = [\"_\".join(x.split(\"_\")[1:-1]) for x in df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_median_evolution(df, [\"ADWIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = os.listdir(results_path)\n",
    "metrics_list = ['no', 'false', 'min','mean', 'median', 'median_true', 'max', 'std']\n",
    "for d_name in [\"nodrift\",\"mooth_concept_drif\", \"abrupt_concept_drif\", \n",
    "        \"abrupt_covariate_drif\"]:#, \"sine2\",\"sine1\",\"stagger\"]:\n",
    "    if(d_name==\"nodrift\"):\n",
    "        single_drift = [f for f in nodrift_funcs if \"nodrift\" in f.__name__]#[:3]\n",
    "    else:\n",
    "        single_drift = [f for f in list_df_generate_fcts if d_name in f.__name__]#[:3]\n",
    "    print(f\"####################{d_name}####################\")\n",
    "    for i,f in enumerate(single_drift[1:-1]):\n",
    "        D_G = f()#generate_abrupt_concept_drift(n_samples=5000)\n",
    "        all_df_metrics = get_D_G_metrics(D_G, results, selected_methods = [\"ADWIN\", \"PH\", \"KSWIN\"],\n",
    "                        exp_type=\"noisy\", noisy = True, path=results_path+\"/\")\n",
    "        if(i==0):\n",
    "            df_drift_res = all_df_metrics\n",
    "        else:\n",
    "            df_drift_res = pd.concat([df_drift_res, all_df_metrics], axis=1)\n",
    "        #all_df_metrics = all_df_metrics.loc[metrics_list].T.sort_values([\"no\",\"false\",\"median\"]).sort_index()\n",
    "        \n",
    "    df_drift_res = df_drift_res.loc[metrics_list].T.sort_values([\"no\",\"false\",\"median\"]).sort_index()\n",
    "    df_drift_res = df_drift_res.drop(columns = [\"no\",\"false\"])\n",
    "    df = df_drift_res.copy()\n",
    "    df['noise_rate'] = [x.split(\"_\")[-1] for x in df.index]\n",
    "    df['algo'] = [\"_\".join(x.split(\"_\")[1:-1]) for x in df.index]\n",
    "\n",
    "\n",
    "    for method in [\"ADWIN\", \"PH\", \"KSWIN\"]:\n",
    "        selected_methods = [method]\n",
    "\n",
    "        ax = plot_median_evolution(df, selected_methods)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reliability\n",
    "## Generate all noise rate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = os.listdir(results_path)\n",
    "metrics_list = ['no', 'false', 'min','mean', 'median', 'median_true', 'max', 'std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = os.listdir(results_path)\n",
    "metrics_list = ['no', 'false', 'min','mean', 'median', 'median_true', 'max', 'std']\n",
    "for d_name in [\"nodrift\"]:#,\"mooth_concept_drif\", \"abrupt_concept_drif\", #nodrift\n",
    "        #\"abrupt_covariate_drif\"]:#, \"sine2\",\"sine1\",\"stagger\"]:\n",
    "    if(d_name==\"nodrift\"):\n",
    "        single_drift = [f for f in nodrift_funcs if \"nodrift\" in f.__name__]#[:3]\n",
    "    else:\n",
    "        single_drift = [f for f in list_df_generate_fcts if d_name in f.__name__]#[:3]\n",
    "    print(f\"####################{d_name}####################\")\n",
    "    for i,f in enumerate(single_drift[:]):\n",
    "        D_G = f()#generate_abrupt_concept_drift(n_samples=5000)\n",
    "        #print(D_G.noise_rate)\n",
    "        if(D_G.noise_rate==0):\n",
    "            all_df_metrics = get_D_G_metrics(D_G, results, selected_methods = [\"ADWIN\", \"PH\", \"KSWIN\"],\n",
    "                            exp_type=\"noisy\", noisy = True, path=results_path+\"/\")            \n",
    "            #print(all_df_metrics, D_G.noise_rate, )\n",
    "            all_df_metrics.columns = [x+\"_0.0\" for x in all_df_metrics.columns]\n",
    "        else:\n",
    "            all_df_metrics = get_D_G_metrics(D_G, results, selected_methods = [\"ADWIN\", \"PH\", \"KSWIN\"],\n",
    "                            exp_type=\"noisy\", noisy = True, path=results_path+\"/\")\n",
    "        if(i==0):\n",
    "            df_drift_res = all_df_metrics\n",
    "        else:\n",
    "            df_drift_res = pd.concat([df_drift_res, all_df_metrics], axis=1)\n",
    "        #all_df_metrics = all_df_metrics.loc[metrics_list].T.sort_values([\"no\",\"false\",\"median\"]).sort_index()\n",
    "        \n",
    "    df_drift_res = df_drift_res.loc[metrics_list].T.sort_values([\"no\",\"false\",\"median\"]).sort_index()\n",
    "    #df_drift_res = df_drift_res.drop(columns = [\"no\",\"false\"])\n",
    "    df_drift_res = df_drift_res[[\"no\",\"false\"]]\n",
    "    df = df_drift_res.copy()\n",
    "    df['noise_rate'] = [x.split(\"_\")[-1] for x in df.index]\n",
    "    df['algo'] = [\"_\".join(x.split(\"_\")[1:-1]) for x in df.index]\n",
    "\n",
    "    df\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_evolving_noise_rates(df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = os.listdir(results_path)\n",
    "metrics_list = ['no', 'false', 'min','mean', 'median', 'median_true', 'max', 'std']\n",
    "for d_name in [\"nodrift\",\"mooth_concept_drif\", \"abrupt_concept_drif\", \"abrupt_covariate_drif\", \"sine2\",\"sine1\",\"stagger\"]:\n",
    "#for d_name in [\"abrupt_covariate_drif\", \"abrupt_covariate_drif\"]:#, \"sine2\",\"sine1\",\"stagger\"]:\n",
    "    if(d_name==\"nodrift\"):\n",
    "        single_drift = [f for f in nodrift_funcs if \"nodrift\" in f.__name__]#[:3]\n",
    "    else:\n",
    "        single_drift = [f for f in list_df_generate_fcts if d_name in f.__name__]#[:3]\n",
    "    print(f\"####################{d_name}####################\")\n",
    "    for i,f in enumerate(single_drift[:]):\n",
    "        D_G = f()#generate_abrupt_concept_drift(n_samples=5000)\n",
    "        if(D_G.noise_rate==0):\n",
    "            all_df_metrics = get_D_G_metrics(D_G, results, selected_methods = [\"ADWIN\", \"PH\", \"KSWIN\"],\n",
    "                            exp_type=\"noisy\", noisy = True, path=results_path+\"/\")            \n",
    "            #print(all_df_metrics, D_G.noise_rate, )\n",
    "            all_df_metrics.columns = [x+\"_0.0\" for x in all_df_metrics.columns]\n",
    "        else:\n",
    "            all_df_metrics = get_D_G_metrics(D_G, results, selected_methods = [\"ADWIN\", \"PH\", \"KSWIN\"],\n",
    "                            exp_type=\"noisy\", noisy = True, path=results_path+\"/\")\n",
    "        if(i==0):\n",
    "            df_drift_res = all_df_metrics\n",
    "        else:\n",
    "            df_drift_res = pd.concat([df_drift_res, all_df_metrics], axis=1)\n",
    "        #all_df_metrics = all_df_metrics.loc[metrics_list].T.sort_values([\"no\",\"false\",\"median\"]).sort_index()\n",
    "        \n",
    "    df_drift_res = df_drift_res.loc[metrics_list].T.sort_values([\"no\",\"false\",\"median\"]).sort_index()\n",
    "    #df_drift_res = df_drift_res.drop(columns = [\"no\",\"false\"])\n",
    "    #df_drift_res = df_drift_res[[\"no\",\"false\"]]\n",
    "    df = df_drift_res.copy()\n",
    "    df['noise_rate'] = [x.split(\"_\")[-1] for x in df.index]\n",
    "    df['algo'] = [\"_\".join(x.split(\"_\")[1:-1]) for x in df.index]\n",
    "\n",
    "\n",
    "    fig, ax = plot_evolving_noise_rates(df, True)\n",
    "\n",
    "    save_path = os.environ.get(\"FIGURES_PATH\")+\"_\".join(single_drift[0].__name__.split(\"_\")[2:])\n",
    "    save_path += 'evolving_detect_rates.png'\n",
    "    print(save_path)\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show all df violins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_methods = [\"ADWIN\", \"PH\", \"KSWIN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare all detectors for a given scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_generate_fcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=8 # Problem from 8\n",
    "for f in list_df_generate_fcts:#[i:i+1]: \n",
    "    D_G = f()\n",
    "    print(\"#\"*20, f\"{D_G.drift_name} {D_G.n}\", \"#\"*20)\n",
    "    if(\"nodrift\" in D_G.drift_name):\n",
    "        continue\n",
    "    if(D_G.noise_rate!=0 ):\n",
    "        df_results_dataset, sep_bar_indexes = get_df_detections(D_G, results,\n",
    "                                                selected_methods, exp_type=\"df_reset\", path=results_path+\"/\", noisy=True)\n",
    "    else:\n",
    "        df_results_dataset, sep_bar_indexes = get_df_detections(D_G, results,\n",
    "                                                selected_methods, exp_type=\"df_reset\", path=results_path+\"/\", noisy=False)\n",
    "\n",
    "    ax = plot_violins(D_G, df_results_dataset, ax=None, sep_bar_indexes=sep_bar_indexes,\n",
    "                            separate_true_false=False);\n",
    "    ax.set_title(f\"{D_G.drift_name}\")\n",
    "    #ax.set_xlim(800,1150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_drift = [f for f in list_df_generate_fcts if \"mooth_concept_drif\" in f.__name__]#[:3]\n",
    "#single_drift = [f for f in list_df_generate_fcts if \"abrupt_concept_drif\" in f.__name__]#[:3]\n",
    "#single_drift = [f for f in list_df_generate_fcts if \"abrupt_covariate_drif\" in f.__name__]#[:3]\n",
    "#single_drift = [f for f in list_df_generate_fcts if \"nodrift\" in f.__name__]#[:3]\n",
    "single_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,f in enumerate(single_drift[:]): \n",
    "    D_G = f()\n",
    "    print(D_G.drift_name.replace(\" \", \"_\"))\n",
    "    #print(\"#\"*20, f\"{D_G.drift_name} {D_G.n}\", \"#\"*20)\n",
    "    df_results_dataset, sep_bar_indexes = get_df_detections(D_G, results,\n",
    "                                                selected_methods, exp_type=\"df_reset\", path=results_path+\"/\", noisy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_G = single_drift[0]()\n",
    "selected_methods = [[\"ADWIN\"],[\"PH\"],[\"KSWIN\"]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_drift = [f for f in list_df_generate_fcts if \"mooth_concept_drif\" in f.__name__]#[:3]\n",
    "#single_drift = [f for f in list_df_generate_fcts if \"abrupt_concept_drif\" in f.__name__]#[:3]\n",
    "#single_drift = [f for f in list_df_generate_fcts if \"abrupt_covariate_drif\" in f.__name__]#[:3]\n",
    "single_drift[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector vs ShapDetect - Noise Variation\n",
    "### For a given selected method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_methods = [\"PH\"]\n",
    "ax = plot_violins_shap_noise(single_drift[:], D_G, selected_methods, results, path=results_path+\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For all selected methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for selected_methods in [[\"ADWIN\"],[\"PH\"],[\"KSWIN\"]]:\n",
    "    ax = plot_violins_shap_noise(single_drift[:], D_G, selected_methods, results, path=results_path+\"/\")\n",
    "    save_path = os.environ.get(\"FIGURES_PATH\")+\"_\".join(single_drift[0].__name__.split(\"_\")[2:])+selected_methods[0]\n",
    "    save_path += 'noise_distrib.png'\n",
    "    print(save_path)\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For several drifts scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = os.listdir(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d_name in [\"mooth_concept_drif\", \"abrupt_concept_drif\", \"abrupt_covariate_drif\", \"sine2\",\"sine1\",\"gradual\"]:#,\"stagger\"][:]:\n",
    "    single_drift = [f for f in list_df_generate_fcts if d_name in f.__name__]\n",
    "    print(\"#\"*20,\"New Drift:\",\"#\"*20)\n",
    "    D_G = single_drift[0]()\n",
    "    print(D_G.drift_name)\n",
    "    for selected_methods in [[\"ADWIN\"],[\"PH\"],[\"KSWIN\"]]:\n",
    "        fig, ax = plot_violins_shap_noise(single_drift, D_G, selected_methods, results, path=results_path+\"/\")\n",
    "        save_path = os.environ.get(\"FIGURES_PATH\")+\"_\".join(single_drift[0].__name__.split(\"_\")[2:])+selected_methods[0]\n",
    "        save_path += 'noise_distrib.png'\n",
    "        print(save_path)\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single drift scenario single detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_methods = [\"KSWIN\"]#['ADWIN', 'PH', 'KSWIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "D_G = list_df_generate_fcts[2]()\n",
    "print(D_G.drift_name, \"#\"*20)\n",
    "df_results_dataset, sep_bar_indexes = get_df_detections(D_G, results,\n",
    "                                                        selected_methods, exp_type=\"df_reset\", path=results_path+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in  [\"retrain_PH_loss\",\"retrain_KSWIN_0\",\"retrain_KSWIN.\", \"retrain_adwin_loss\"]:\n",
    "    for real_col in df_results_dataset.columns:\n",
    "        if(col in real_col):\n",
    "            df_results_dataset = df_results_dataset.drop(columns=[real_col])\n",
    "            print(f\"{real_col} dropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add metrics name before labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_dataset.columns = [x.replace(\"_loss\",\"\") for x in df_results_dataset.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_violins(D_G, df_results_dataset.iloc[:,:], ax=None, sep_bar_indexes=sep_bar_indexes, separate_true_false=False);\n",
    "#ax.set_xlim(800,1150)\n",
    "\n",
    "\n",
    "#plt.legend([])\n",
    "save_path = os.environ.get(\"FIGURES_PATH\")+D_G.drift_name.replace(\" \",\"_\")\n",
    "save_path += 'noisy_'+selected_methods[0]+'_compare.png'\n",
    "print(save_path)\n",
    "plt.savefig(save_path, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_violins(D_G, df_results_dataset.iloc[:,:], ax=None, sep_bar_indexes=sep_bar_indexes, separate_true_false=False);\n",
    "#ax.set_xlim(800,1150)\n",
    "\n",
    "\n",
    "#plt.legend([])\n",
    "save_path = os.environ.get(\"FIGURES_PATH\")+D_G.drift_name.replace(\" \",\"_\")\n",
    "save_path += 'noisy_'+selected_methods[0]+'_compare.png'\n",
    "print(save_path)\n",
    "plt.savefig(save_path, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
